{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 5s 32ms/step - loss: 4.2725 - acc: 0.6235\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tasneem/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 24ms/step - loss: 3.0149 - acc: 0.5309\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.6200 - acc: 0.6296\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.0283 - acc: 0.6049\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9138 - acc: 0.6543\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8229 - acc: 0.6481\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8933 - acc: 0.6543\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6794 - acc: 0.7716\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7788 - acc: 0.6790\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7323 - acc: 0.7284\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6638 - acc: 0.7407\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6564 - acc: 0.8148\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6180 - acc: 0.8086\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6959 - acc: 0.7901\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6330 - acc: 0.7654\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6752 - acc: 0.7531\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5635 - acc: 0.8272\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6067 - acc: 0.7901\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5809 - acc: 0.7778\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5355 - acc: 0.8519\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5499 - acc: 0.8148\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4360 - acc: 0.8951\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5640 - acc: 0.7778\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4950 - acc: 0.8457\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5496 - acc: 0.8148\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5504 - acc: 0.8395\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5283 - acc: 0.8086\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3813 - acc: 0.8580\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4649 - acc: 0.8765\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4050 - acc: 0.8457\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4031 - acc: 0.8580\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3794 - acc: 0.9074\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3611 - acc: 0.9198\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5188 - acc: 0.8395\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4696 - acc: 0.8395\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4405 - acc: 0.8765\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4652 - acc: 0.8642\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3574 - acc: 0.9074\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4171 - acc: 0.8704\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3699 - acc: 0.9074\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4137 - acc: 0.8642\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4950 - acc: 0.8827\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3215 - acc: 0.9198\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3517 - acc: 0.8827\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3762 - acc: 0.8951\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.3737 - acc: 0.8765\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4013 - acc: 0.8889\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.3653 - acc: 0.8889\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.3876 - acc: 0.8827\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4518 - acc: 0.8889\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 5s 33ms/step - loss: 3.5102 - acc: 0.6420\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 2.8400 - acc: 0.6728\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 2.3795 - acc: 0.7222\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 1.3818 - acc: 0.7284\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 1.1496 - acc: 0.7222\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.9523 - acc: 0.7037\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.7796 - acc: 0.7654\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.7713 - acc: 0.7531\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6500 - acc: 0.7963\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6366 - acc: 0.8148\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5713 - acc: 0.8457\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5532 - acc: 0.8395\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5754 - acc: 0.8025\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5394 - acc: 0.8272\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6367 - acc: 0.7654\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4726 - acc: 0.8580\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6563 - acc: 0.7531\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5301 - acc: 0.8272\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5259 - acc: 0.8086\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5762 - acc: 0.8395\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4548 - acc: 0.8642\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.7022 - acc: 0.8148\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5142 - acc: 0.8395\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5687 - acc: 0.8148\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4478 - acc: 0.8889\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5320 - acc: 0.8765\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4350 - acc: 0.8457\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4558 - acc: 0.8519\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4470 - acc: 0.8642\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4763 - acc: 0.8642\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4122 - acc: 0.8889\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3794 - acc: 0.8704\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5761 - acc: 0.8642\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4977 - acc: 0.8457\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4456 - acc: 0.8395\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4672 - acc: 0.8704\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4138 - acc: 0.8765\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4902 - acc: 0.8642\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4086 - acc: 0.8827\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3803 - acc: 0.8765\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4011 - acc: 0.8765\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3421 - acc: 0.9012\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3584 - acc: 0.8889\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3381 - acc: 0.8951\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4150 - acc: 0.9074\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3746 - acc: 0.8827\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3358 - acc: 0.9136\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3989 - acc: 0.8704\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4191 - acc: 0.8827\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3645 - acc: 0.9074\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 5s 33ms/step - loss: 5.0831 - acc: 0.5617\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.6707 - acc: 0.6481\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.8377 - acc: 0.6420\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9514 - acc: 0.6728\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9732 - acc: 0.7160\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8859 - acc: 0.7160\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7395 - acc: 0.8148\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6528 - acc: 0.7963\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6781 - acc: 0.7840\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7048 - acc: 0.8148\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6748 - acc: 0.7531\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.6791 - acc: 0.8148\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5736 - acc: 0.8025\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5763 - acc: 0.8148\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6384 - acc: 0.7840\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4773 - acc: 0.8642\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.6040 - acc: 0.8333\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6518 - acc: 0.7778\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6770 - acc: 0.7778\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5864 - acc: 0.8210\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4806 - acc: 0.8519\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4671 - acc: 0.8704\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4758 - acc: 0.8827\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4981 - acc: 0.8704\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4469 - acc: 0.8457\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4751 - acc: 0.8395\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3976 - acc: 0.8704\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3935 - acc: 0.8951\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6127 - acc: 0.8148\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4991 - acc: 0.8704\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5036 - acc: 0.8025\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4459 - acc: 0.8765\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4156 - acc: 0.8642\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4181 - acc: 0.8704\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4376 - acc: 0.8827\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4987 - acc: 0.8333\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4432 - acc: 0.8765\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4150 - acc: 0.8704\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4837 - acc: 0.8457\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3301 - acc: 0.9444\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3259 - acc: 0.9321\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3485 - acc: 0.8889\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4366 - acc: 0.8827\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4482 - acc: 0.8580\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3430 - acc: 0.8951\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3563 - acc: 0.9074\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3729 - acc: 0.8951\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4083 - acc: 0.8642\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4292 - acc: 0.8827\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3709 - acc: 0.9012\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 4.5489 - acc: 0.6296\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.0778 - acc: 0.6173\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1715 - acc: 0.7654\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1905 - acc: 0.6790\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8405 - acc: 0.6975\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8116 - acc: 0.7099\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6810 - acc: 0.7407\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6379 - acc: 0.8086\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7386 - acc: 0.7531\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7594 - acc: 0.7222\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7073 - acc: 0.7531\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5709 - acc: 0.7840\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5680 - acc: 0.7654\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5838 - acc: 0.7840\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4918 - acc: 0.8272\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4531 - acc: 0.8889\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4822 - acc: 0.8642\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5008 - acc: 0.8395\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6154 - acc: 0.7840\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5577 - acc: 0.8210\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4554 - acc: 0.8827\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4193 - acc: 0.8642\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4632 - acc: 0.8210\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4648 - acc: 0.8519\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3966 - acc: 0.8642\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5195 - acc: 0.8210\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4219 - acc: 0.8889\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4684 - acc: 0.8519\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4508 - acc: 0.8395\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4420 - acc: 0.8704\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3802 - acc: 0.8889\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4460 - acc: 0.8642\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3720 - acc: 0.8642\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.2658 - acc: 0.9568\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.2847 - acc: 0.9383\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3705 - acc: 0.8580\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3879 - acc: 0.9074\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3452 - acc: 0.8827\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3423 - acc: 0.9012\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4085 - acc: 0.8765\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5305 - acc: 0.8086\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4590 - acc: 0.8765\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3722 - acc: 0.8827\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.2865 - acc: 0.9198\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3688 - acc: 0.8642\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3846 - acc: 0.8827\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3747 - acc: 0.8765\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3571 - acc: 0.9074\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3200 - acc: 0.9012\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3463 - acc: 0.9198\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 3.9872 - acc: 0.6358\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 2.1120 - acc: 0.7099\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.0370 - acc: 0.6852\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.4734 - acc: 0.6605\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8480 - acc: 0.7037\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7136 - acc: 0.7654\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7130 - acc: 0.7593\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7575 - acc: 0.7593\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5899 - acc: 0.8025\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7520 - acc: 0.7407\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6684 - acc: 0.7716\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5999 - acc: 0.7901\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6043 - acc: 0.8025\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5098 - acc: 0.8086\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5925 - acc: 0.7716\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5258 - acc: 0.8210\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5042 - acc: 0.8210\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5296 - acc: 0.8148\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5102 - acc: 0.8395\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4787 - acc: 0.8519\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4572 - acc: 0.8704\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5757 - acc: 0.8272\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4406 - acc: 0.8457\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4536 - acc: 0.8642\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4099 - acc: 0.9136\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4630 - acc: 0.8580\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3979 - acc: 0.8765\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3861 - acc: 0.9012\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5644 - acc: 0.8272\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4698 - acc: 0.8457\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4244 - acc: 0.8333\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4698 - acc: 0.8642\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5455 - acc: 0.8272\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4441 - acc: 0.8889\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4140 - acc: 0.8642\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4174 - acc: 0.8704\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5343 - acc: 0.8519\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4061 - acc: 0.8827\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3941 - acc: 0.8519\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3684 - acc: 0.8580\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4853 - acc: 0.8765\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3354 - acc: 0.9012\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3406 - acc: 0.8765\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.2761 - acc: 0.9383\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4451 - acc: 0.8642\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4223 - acc: 0.8580\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3832 - acc: 0.9012\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3664 - acc: 0.8951\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3687 - acc: 0.8889\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3697 - acc: 0.8704\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 4.0486 - acc: 0.5802\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.3193 - acc: 0.5988\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1309 - acc: 0.7160\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9269 - acc: 0.7160\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8053 - acc: 0.6296\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7315 - acc: 0.7284\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7059 - acc: 0.7593\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5802 - acc: 0.7963\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6393 - acc: 0.8086\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5707 - acc: 0.7778\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6963 - acc: 0.7716\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6521 - acc: 0.8025\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5192 - acc: 0.8148\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5647 - acc: 0.8148\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4931 - acc: 0.8333\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4642 - acc: 0.8519\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4454 - acc: 0.8704\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4335 - acc: 0.8951\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5915 - acc: 0.8086\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5491 - acc: 0.8457\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3939 - acc: 0.9012\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3833 - acc: 0.8889\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3683 - acc: 0.8951\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3587 - acc: 0.8889\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4719 - acc: 0.8704\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6449 - acc: 0.7901\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4901 - acc: 0.8086\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3961 - acc: 0.8951\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4295 - acc: 0.8951\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4268 - acc: 0.8827\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3906 - acc: 0.8951\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3558 - acc: 0.9012\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3321 - acc: 0.9012\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4430 - acc: 0.8765\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3555 - acc: 0.8951\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4073 - acc: 0.8889\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7576 - acc: 0.7593\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6919 - acc: 0.7284\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5998 - acc: 0.7284\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5444 - acc: 0.8210\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3685 - acc: 0.9136\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4493 - acc: 0.8580\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4507 - acc: 0.8580\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4665 - acc: 0.8395\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3852 - acc: 0.8889\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3839 - acc: 0.8951\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3590 - acc: 0.9012\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4214 - acc: 0.8765\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3359 - acc: 0.9136\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4431 - acc: 0.8827\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 4.5277 - acc: 0.5679\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.3920 - acc: 0.6605\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.9998 - acc: 0.5617\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1734 - acc: 0.6481\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9228 - acc: 0.6605\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9344 - acc: 0.6543\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7810 - acc: 0.7284\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7856 - acc: 0.7346\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7401 - acc: 0.7346\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6797 - acc: 0.7346\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6573 - acc: 0.7716\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4604 - acc: 0.8519\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5895 - acc: 0.8333\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5553 - acc: 0.8765\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5944 - acc: 0.8148\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5275 - acc: 0.8395\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5291 - acc: 0.8765\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7571 - acc: 0.8333\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5308 - acc: 0.8272\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4631 - acc: 0.8704\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5075 - acc: 0.8210\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5061 - acc: 0.8519\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3936 - acc: 0.8827\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4059 - acc: 0.8704\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4815 - acc: 0.8210\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4975 - acc: 0.8642\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4654 - acc: 0.8889\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4164 - acc: 0.9012\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4212 - acc: 0.8333\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3945 - acc: 0.9012\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4280 - acc: 0.8457\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4394 - acc: 0.8765\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4233 - acc: 0.8642\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4349 - acc: 0.8765\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4317 - acc: 0.8519\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3433 - acc: 0.9259\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3177 - acc: 0.9198\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4307 - acc: 0.8395\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3701 - acc: 0.8951\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3873 - acc: 0.9074\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4266 - acc: 0.8580\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3953 - acc: 0.8827\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3497 - acc: 0.9321\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3916 - acc: 0.8765\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3072 - acc: 0.9321\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3359 - acc: 0.8951\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3637 - acc: 0.8889\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3799 - acc: 0.8765\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3567 - acc: 0.8827\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.2703 - acc: 0.9691\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 4.4060 - acc: 0.5123\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.4183 - acc: 0.5494\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.7098 - acc: 0.4568\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.4188 - acc: 0.4630\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1526 - acc: 0.4630\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.0998 - acc: 0.5864\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1922 - acc: 0.4630\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1991 - acc: 0.4259\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1130 - acc: 0.4877\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.0671 - acc: 0.4691\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.2355 - acc: 0.4321\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.1159 - acc: 0.4815\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.0014 - acc: 0.5556\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9099 - acc: 0.6420\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7965 - acc: 0.6728\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7381 - acc: 0.7160\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7060 - acc: 0.7284\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7095 - acc: 0.7099\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6927 - acc: 0.7963\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6394 - acc: 0.7901\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6616 - acc: 0.7654\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5213 - acc: 0.7901\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5717 - acc: 0.8025\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5350 - acc: 0.8148\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4942 - acc: 0.8272\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5118 - acc: 0.8148\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5233 - acc: 0.8210\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5275 - acc: 0.8519\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4773 - acc: 0.8333\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3955 - acc: 0.8704\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4519 - acc: 0.8333\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6013 - acc: 0.8210\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4771 - acc: 0.8333\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4533 - acc: 0.8765\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4763 - acc: 0.8086\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3418 - acc: 0.9012\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3689 - acc: 0.8765\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4264 - acc: 0.8642\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3439 - acc: 0.9136\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3840 - acc: 0.8642\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4158 - acc: 0.8395\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3974 - acc: 0.8642\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5669 - acc: 0.8333\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4102 - acc: 0.8457\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4694 - acc: 0.8580\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4559 - acc: 0.8457\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3727 - acc: 0.8827\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3847 - acc: 0.8580\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3451 - acc: 0.8889\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3294 - acc: 0.9259\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179] [144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161]\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 3.5285 - acc: 0.6667\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.5817 - acc: 0.6914\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.4199 - acc: 0.6667\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.2732 - acc: 0.7469\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7641 - acc: 0.7346\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7631 - acc: 0.7593\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7646 - acc: 0.7160\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8326 - acc: 0.7716\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7277 - acc: 0.7716\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5756 - acc: 0.8025\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5615 - acc: 0.8519\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6113 - acc: 0.7778\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5716 - acc: 0.8086\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5863 - acc: 0.7901\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5861 - acc: 0.8210\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6182 - acc: 0.7840\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4822 - acc: 0.8580\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4615 - acc: 0.8333\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5248 - acc: 0.8519\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5853 - acc: 0.7840\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5528 - acc: 0.8519\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5811 - acc: 0.8395\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5204 - acc: 0.8519\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5132 - acc: 0.8519\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5361 - acc: 0.7840\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3824 - acc: 0.8951\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4828 - acc: 0.8457\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5715 - acc: 0.7901\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4357 - acc: 0.8765\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4418 - acc: 0.8457\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3355 - acc: 0.9074\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3502 - acc: 0.8889\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4242 - acc: 0.8951\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3450 - acc: 0.8951\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3765 - acc: 0.8827\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4581 - acc: 0.8827\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4788 - acc: 0.8704\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5160 - acc: 0.8704\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3651 - acc: 0.9012\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3679 - acc: 0.9136\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4468 - acc: 0.8395\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3521 - acc: 0.8951\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3419 - acc: 0.9136\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3448 - acc: 0.9383\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3752 - acc: 0.8951\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4578 - acc: 0.8519\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5329 - acc: 0.8148\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4643 - acc: 0.8519\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3978 - acc: 0.8889\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4198 - acc: 0.8827\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161] [162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 4.3005 - acc: 0.5988\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 3.3922 - acc: 0.6420\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 2.0155 - acc: 0.6358\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.3911 - acc: 0.6358\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 1.2387 - acc: 0.6235\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8942 - acc: 0.6481\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9473 - acc: 0.7284\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.9443 - acc: 0.5988\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7342 - acc: 0.7407\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.8505 - acc: 0.7284\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7207 - acc: 0.7346\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6835 - acc: 0.7840\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6987 - acc: 0.7778\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7289 - acc: 0.8086\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6237 - acc: 0.7716\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5415 - acc: 0.8395\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6420 - acc: 0.7901\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.6601 - acc: 0.7407\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.7218 - acc: 0.7840\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5492 - acc: 0.7963\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5475 - acc: 0.8148\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5720 - acc: 0.8457\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5069 - acc: 0.8272\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4778 - acc: 0.8333\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5450 - acc: 0.8025\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4867 - acc: 0.8580\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4850 - acc: 0.8519\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4704 - acc: 0.8580\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3993 - acc: 0.8889\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3654 - acc: 0.9012\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3396 - acc: 0.9136\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4428 - acc: 0.8704\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5859 - acc: 0.8519\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5813 - acc: 0.7778\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4544 - acc: 0.8827\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5436 - acc: 0.8457\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4446 - acc: 0.8765\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4194 - acc: 0.8395\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4049 - acc: 0.8951\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4420 - acc: 0.8395\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4263 - acc: 0.8642\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4287 - acc: 0.8765\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4331 - acc: 0.8765\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3901 - acc: 0.8704\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4121 - acc: 0.8457\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4841 - acc: 0.8519\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4461 - acc: 0.8827\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.3088 - acc: 0.9259\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4107 - acc: 0.8827\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.2852 - acc: 0.9198\n",
      "18/18 [==============================] - 1s 59ms/step\n",
      "test loss\n",
      "0.30407264828681946\n",
      "test accuracy\n",
      "1.0\n",
      "AUC_ROC\n",
      "0.9958333333333332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"X_test.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y, num_classes=3)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "\n",
    "cvacc =[]\n",
    "cvAUC=[]\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf=KFold(n_splits=10, random_state=10, shuffle=False)\n",
    "for train_index, test_index, in kf.split(X_train):\n",
    "    print(\"%s %s\" % (train_index, test_index))\n",
    "    X_train_c, X_test_c = X_train[train_index], X_train[test_index]\n",
    "    y_train_c, y_test_c = y_train[train_index], y_train[test_index]\n",
    "    reg=keras.regularizers.l2(0.0005)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(560, (3, 3), activation ='relu', input_shape=(200, 200, 3), kernel_regularizer=reg, \n",
    "                     bias_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(280, (3, 3), activation ='relu', kernel_regularizer=reg, bias_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(140, (3, 3), activation ='relu', kernel_regularizer=reg, bias_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(70, (3, 3), activation ='relu', kernel_regularizer=reg, bias_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, activation ='relu', kernel_regularizer=reg, bias_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation ='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(3, activation ='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    model.load_weights('weights_cnn_model2_6.h5')\n",
    "    \n",
    "    cb= ModelCheckpoint(filepath='weights_cnn_best_crossvalidation.h5',  verbose=1, monitor='val_acc', \n",
    "                        save_best_only=True, save_weights_only=True)\n",
    "     #validation_split=0.1,\n",
    "    history=model.fit(X_train_c, y_train_c, batch_size=10, epochs=50, callbacks=[cb])\n",
    "    \n",
    "    '''print(history.history.keys())\n",
    "\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    score, acc=model.evaluate( X_test_c, y_test_c)\n",
    "    print('test loss')\n",
    "    print(score)\n",
    "    print ('test accuracy')\n",
    "    print(acc)\n",
    "    cvacc.append(acc)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_test_c)\n",
    "    auc_value=sklearn.metrics.roc_auc_score(y_test_c, y_pred)\n",
    "    print ('AUC_ROC')\n",
    "    print(auc_value)\n",
    "    cvAUC.append(auc_value)\n",
    "\n",
    "    # Plot of a ROC curve for a specific class\n",
    "    \n",
    "    def plot_ROC(y_test,y_pred):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "   \n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(3):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            print(roc_auc)\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # Plot of a ROC curve for a specific class\n",
    "        for i in range(3):\n",
    "            plt.figure()\n",
    "            plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f})'.format(roc_auc[i]))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic example')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "    import itertools \n",
    "    cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    print('confusion matrix of : ',cm)\n",
    "\n",
    "    def plot_confusion_matrix(cm, classes,\n",
    "                             normalize=False,\n",
    "                             title='confusion matrix',\n",
    "                             cmap=plt.cm.Reds):\n",
    "        # this funcation print & plots confusion matrix\n",
    "        # normalize can be applied by  normalize=True,\n",
    "        plt.figure()\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks= np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        if normalize:\n",
    "            cm= cm.astype('float')/ cm.sum(axis=1)[:, np.newaxis]\n",
    "            print('normalized confusion matrix')\n",
    "        else:\n",
    "            print(' confusion matrix, without normalized')\n",
    "        print(cm)\n",
    "        thresh=cm.max()/2.\n",
    "        for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i,j],\n",
    "                    horizontalalignment='center',\n",
    "                    color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('true label')\n",
    "        plt.xlabel('predicted label')\n",
    "\n",
    "        input to confusion_matrix must be a list of predictions, not OHEs (one hot encodings). \n",
    "        Call argmax on your y_test and y_pred, and you should get what you expect.\n",
    "\n",
    "        from sklearn.utils.multiclass import unique_labels\n",
    "        classes = [1,2,3]\n",
    "        plot_confusion_matrix(cm,classes)'''\n",
    "        \n",
    "\n",
    "score, acc=model.evaluate( X_test_c, y_test_c)\n",
    "print('test loss')\n",
    "print(score)\n",
    "print ('test accuracy')\n",
    "print(acc)\n",
    "cvacc.append(acc)\n",
    "    \n",
    "y_pred = model.predict_proba(X_test_c)\n",
    "auc_value=sklearn.metrics.roc_auc_score(y_test_c, y_pred)\n",
    "print ('AUC_ROC')\n",
    "print(auc_value)\n",
    "cvAUC.append(auc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kfold_right_100acc_99.5auc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c970e77867c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The mean accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvacc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The mean AUC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvAUC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy')\n",
    "print(np.mean(cvacc))\n",
    "\n",
    "print('The mean AUC')\n",
    "print(np.mean(cvAUC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
