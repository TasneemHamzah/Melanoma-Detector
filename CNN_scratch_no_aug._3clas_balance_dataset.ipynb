{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-conv-32-nodes-0-dense-1550886788-5x5-kernal-50epochs-2x2maxpooling\n",
      "Train on 610 samples, validate on 262 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.1009 - acc: 0.3623 - val_loss: 1.0995 - val_acc: 0.3015\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0886 - acc: 0.4115 - val_loss: 1.0441 - val_acc: 0.4771\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 1.0836 - acc: 0.4443 - val_loss: 1.0703 - val_acc: 0.3969\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0592 - acc: 0.4541 - val_loss: 1.0214 - val_acc: 0.3855\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0046 - acc: 0.5131 - val_loss: 1.0448 - val_acc: 0.4466\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0074 - acc: 0.5098 - val_loss: 0.9482 - val_acc: 0.5191\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.9191 - acc: 0.5393 - val_loss: 0.8561 - val_acc: 0.5611\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8827 - acc: 0.5902 - val_loss: 0.8587 - val_acc: 0.6069\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8689 - acc: 0.5869 - val_loss: 0.8828 - val_acc: 0.5382\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8642 - acc: 0.5984 - val_loss: 0.8026 - val_acc: 0.6221\n",
      "Epoch 11/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8517 - acc: 0.5902 - val_loss: 0.8628 - val_acc: 0.5763\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8564 - acc: 0.6131 - val_loss: 0.8274 - val_acc: 0.5916\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8446 - acc: 0.6098 - val_loss: 0.8537 - val_acc: 0.5878\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8277 - acc: 0.6295 - val_loss: 0.9260 - val_acc: 0.5725\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.9184 - acc: 0.5508 - val_loss: 0.8142 - val_acc: 0.5954\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8618 - acc: 0.5836 - val_loss: 0.8098 - val_acc: 0.5763\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8409 - acc: 0.6246 - val_loss: 0.8728 - val_acc: 0.6069\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8223 - acc: 0.6377 - val_loss: 0.8251 - val_acc: 0.6145\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7764 - acc: 0.6410 - val_loss: 0.8083 - val_acc: 0.6031\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7931 - acc: 0.6525 - val_loss: 0.8165 - val_acc: 0.6107\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.8017 - acc: 0.6623 - val_loss: 0.8853 - val_acc: 0.6679\n",
      "Epoch 22/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7810 - acc: 0.6754 - val_loss: 0.8154 - val_acc: 0.6374\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7475 - acc: 0.6918 - val_loss: 0.8087 - val_acc: 0.6107\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7747 - acc: 0.6852 - val_loss: 0.8928 - val_acc: 0.5649\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7326 - acc: 0.6607 - val_loss: 0.8960 - val_acc: 0.5611\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7270 - acc: 0.6754 - val_loss: 0.8007 - val_acc: 0.6756\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6619 - acc: 0.7082 - val_loss: 0.7912 - val_acc: 0.6908\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6827 - acc: 0.7066 - val_loss: 0.7881 - val_acc: 0.7099\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6725 - acc: 0.7197 - val_loss: 0.8236 - val_acc: 0.6947\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6838 - acc: 0.6918 - val_loss: 0.8116 - val_acc: 0.6985\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.7456 - acc: 0.6525 - val_loss: 0.7918 - val_acc: 0.6832\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6893 - acc: 0.7000 - val_loss: 0.8526 - val_acc: 0.6603\n",
      "Epoch 33/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6641 - acc: 0.6984 - val_loss: 0.8859 - val_acc: 0.6489\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6643 - acc: 0.7180 - val_loss: 0.8471 - val_acc: 0.7099\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6274 - acc: 0.7295 - val_loss: 0.8493 - val_acc: 0.6756\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6760 - acc: 0.7000 - val_loss: 0.7962 - val_acc: 0.6832\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6193 - acc: 0.7098 - val_loss: 0.7947 - val_acc: 0.6870\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.6353 - acc: 0.7098 - val_loss: 0.8097 - val_acc: 0.6870\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5873 - acc: 0.7393 - val_loss: 1.0089 - val_acc: 0.6908\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.5905 - acc: 0.7328 - val_loss: 0.8365 - val_acc: 0.6832\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5891 - acc: 0.7623 - val_loss: 0.8541 - val_acc: 0.7137\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5578 - acc: 0.7541 - val_loss: 0.9529 - val_acc: 0.6679\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5501 - acc: 0.7656 - val_loss: 0.9410 - val_acc: 0.6527\n",
      "Epoch 44/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5355 - acc: 0.7770 - val_loss: 0.9022 - val_acc: 0.6718\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5373 - acc: 0.7590 - val_loss: 0.9923 - val_acc: 0.6603\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5480 - acc: 0.7836 - val_loss: 0.8938 - val_acc: 0.6947\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5823 - acc: 0.7525 - val_loss: 0.9039 - val_acc: 0.6794\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5723 - acc: 0.7689 - val_loss: 0.8697 - val_acc: 0.6947\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5553 - acc: 0.7803 - val_loss: 0.9950 - val_acc: 0.6870\n",
      "Epoch 50/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 0.5058 - acc: 0.7787 - val_loss: 0.9820 - val_acc: 0.6947\n",
      "5-conv-64-nodes-0-dense-1550886870-5x5-kernal-50epochs-2x2maxpooling\n",
      "Train on 610 samples, validate on 262 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.1139 - acc: 0.3869 - val_loss: 0.9772 - val_acc: 0.4580\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0564 - acc: 0.4066 - val_loss: 1.0998 - val_acc: 0.3015\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0924 - acc: 0.3492 - val_loss: 1.0242 - val_acc: 0.3473\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0574 - acc: 0.4311 - val_loss: 0.9536 - val_acc: 0.4504\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.1020 - acc: 0.4705 - val_loss: 1.0587 - val_acc: 0.3550\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0336 - acc: 0.4557 - val_loss: 0.9693 - val_acc: 0.4504\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9972 - acc: 0.5082 - val_loss: 0.9845 - val_acc: 0.4237\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9775 - acc: 0.5131 - val_loss: 0.9532 - val_acc: 0.4542\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9522 - acc: 0.5164 - val_loss: 0.9373 - val_acc: 0.4656\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9512 - acc: 0.5197 - val_loss: 0.9382 - val_acc: 0.4656\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9424 - acc: 0.5279 - val_loss: 0.9553 - val_acc: 0.4542\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9486 - acc: 0.5213 - val_loss: 0.9547 - val_acc: 0.4618\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9312 - acc: 0.5213 - val_loss: 0.9385 - val_acc: 0.4656\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9319 - acc: 0.5344 - val_loss: 0.9569 - val_acc: 0.4733\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9081 - acc: 0.5443 - val_loss: 0.9392 - val_acc: 0.4809\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9166 - acc: 0.5361 - val_loss: 0.9681 - val_acc: 0.4618\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8955 - acc: 0.5459 - val_loss: 0.9457 - val_acc: 0.4695\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9218 - acc: 0.5377 - val_loss: 0.9310 - val_acc: 0.4771\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9059 - acc: 0.5459 - val_loss: 0.9423 - val_acc: 0.4733\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9034 - acc: 0.5377 - val_loss: 0.9660 - val_acc: 0.4771\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.9098 - acc: 0.5361 - val_loss: 0.9753 - val_acc: 0.4389\n",
      "Epoch 22/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8934 - acc: 0.5377 - val_loss: 0.9404 - val_acc: 0.4847\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8966 - acc: 0.5443 - val_loss: 0.9542 - val_acc: 0.4618\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8813 - acc: 0.5443 - val_loss: 0.9497 - val_acc: 0.4580\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8612 - acc: 0.5508 - val_loss: 0.9472 - val_acc: 0.4695\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8694 - acc: 0.5541 - val_loss: 0.9390 - val_acc: 0.4809\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8642 - acc: 0.5410 - val_loss: 0.9480 - val_acc: 0.4771\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8442 - acc: 0.5574 - val_loss: 0.9672 - val_acc: 0.4695\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8513 - acc: 0.5557 - val_loss: 0.9746 - val_acc: 0.4695\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 3s 4ms/step - loss: 0.8614 - acc: 0.5492 - val_loss: 0.9590 - val_acc: 0.4771\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8472 - acc: 0.5607 - val_loss: 0.9970 - val_acc: 0.4771\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8573 - acc: 0.5443 - val_loss: 0.9883 - val_acc: 0.4542\n",
      "Epoch 33/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8556 - acc: 0.5590 - val_loss: 0.9492 - val_acc: 0.4733\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8398 - acc: 0.5574 - val_loss: 0.9475 - val_acc: 0.4656\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8290 - acc: 0.5656 - val_loss: 0.9836 - val_acc: 0.4695\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8275 - acc: 0.5639 - val_loss: 0.9496 - val_acc: 0.4733\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8303 - acc: 0.5623 - val_loss: 1.0079 - val_acc: 0.4809\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8400 - acc: 0.5574 - val_loss: 0.9728 - val_acc: 0.4618\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8284 - acc: 0.5574 - val_loss: 0.9777 - val_acc: 0.4733\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8248 - acc: 0.5639 - val_loss: 1.0593 - val_acc: 0.4847\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8156 - acc: 0.5672 - val_loss: 1.0184 - val_acc: 0.4656\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8092 - acc: 0.5689 - val_loss: 1.1116 - val_acc: 0.4542\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8344 - acc: 0.5541 - val_loss: 1.0620 - val_acc: 0.4771\n",
      "Epoch 44/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8186 - acc: 0.5738 - val_loss: 0.9823 - val_acc: 0.4695\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8150 - acc: 0.5656 - val_loss: 1.0611 - val_acc: 0.4618\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8218 - acc: 0.5656 - val_loss: 0.9763 - val_acc: 0.4313\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8533 - acc: 0.5639 - val_loss: 1.0459 - val_acc: 0.4771\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8261 - acc: 0.5672 - val_loss: 1.0248 - val_acc: 0.4656\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.7911 - acc: 0.5770 - val_loss: 1.0727 - val_acc: 0.4695\n",
      "Epoch 50/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 0.8174 - acc: 0.5689 - val_loss: 1.0750 - val_acc: 0.4809\n",
      "5-conv-128-nodes-0-dense-1550887013-5x5-kernal-50epochs-2x2maxpooling\n",
      "Train on 610 samples, validate on 262 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 6s 9ms/step - loss: 1.1158 - acc: 0.4131 - val_loss: 1.0665 - val_acc: 0.3817\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.0243 - acc: 0.4623 - val_loss: 1.0880 - val_acc: 0.4580\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.0494 - acc: 0.4787 - val_loss: 0.9517 - val_acc: 0.4389\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.0616 - acc: 0.4770 - val_loss: 1.0448 - val_acc: 0.4198\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.0124 - acc: 0.4852 - val_loss: 0.9397 - val_acc: 0.4618\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9875 - acc: 0.5148 - val_loss: 0.9054 - val_acc: 0.5153\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9343 - acc: 0.5377 - val_loss: 0.8791 - val_acc: 0.5153\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9328 - acc: 0.5393 - val_loss: 0.8768 - val_acc: 0.5229\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9572 - acc: 0.5213 - val_loss: 0.9089 - val_acc: 0.4962\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8994 - acc: 0.5492 - val_loss: 0.8833 - val_acc: 0.5267\n",
      "Epoch 11/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9500 - acc: 0.5393 - val_loss: 0.9746 - val_acc: 0.5763\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9409 - acc: 0.5344 - val_loss: 0.8666 - val_acc: 0.5687\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9366 - acc: 0.5541 - val_loss: 0.8768 - val_acc: 0.5725\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.9016 - acc: 0.5590 - val_loss: 0.8674 - val_acc: 0.5611\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 0.8782 - acc: 0.5607 - val_loss: 0.9177 - val_acc: 0.5076\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8961 - acc: 0.5623 - val_loss: 0.8577 - val_acc: 0.5649\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8630 - acc: 0.5770 - val_loss: 0.8531 - val_acc: 0.5840\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8572 - acc: 0.5852 - val_loss: 0.8415 - val_acc: 0.5687\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8473 - acc: 0.6000 - val_loss: 0.8464 - val_acc: 0.5992\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8432 - acc: 0.6000 - val_loss: 0.8517 - val_acc: 0.6260\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8252 - acc: 0.5869 - val_loss: 0.8577 - val_acc: 0.5992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8314 - acc: 0.6016 - val_loss: 0.8634 - val_acc: 0.6183\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8635 - acc: 0.6148 - val_loss: 0.8653 - val_acc: 0.6107\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8152 - acc: 0.6197 - val_loss: 0.8316 - val_acc: 0.6336\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8106 - acc: 0.6066 - val_loss: 0.8593 - val_acc: 0.6565\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7784 - acc: 0.6443 - val_loss: 0.8296 - val_acc: 0.6985\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7646 - acc: 0.6656 - val_loss: 0.8058 - val_acc: 0.6832\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7791 - acc: 0.6508 - val_loss: 0.8748 - val_acc: 0.6489\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7638 - acc: 0.6508 - val_loss: 0.8650 - val_acc: 0.6489\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7491 - acc: 0.6607 - val_loss: 0.8242 - val_acc: 0.7061\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7561 - acc: 0.6770 - val_loss: 0.8336 - val_acc: 0.7023\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7259 - acc: 0.6918 - val_loss: 0.8446 - val_acc: 0.6565\n",
      "Epoch 33/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7460 - acc: 0.6885 - val_loss: 0.8676 - val_acc: 0.6679\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7040 - acc: 0.7016 - val_loss: 0.8351 - val_acc: 0.7023\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.8389 - acc: 0.6475 - val_loss: 0.8075 - val_acc: 0.6679\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7601 - acc: 0.6885 - val_loss: 0.8705 - val_acc: 0.6985\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7218 - acc: 0.6885 - val_loss: 0.8795 - val_acc: 0.7023\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7430 - acc: 0.6836 - val_loss: 0.8417 - val_acc: 0.6985\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7427 - acc: 0.6951 - val_loss: 0.8425 - val_acc: 0.6489\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.7305 - acc: 0.6902 - val_loss: 0.8349 - val_acc: 0.7176\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6824 - acc: 0.7098 - val_loss: 0.8329 - val_acc: 0.7328\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6521 - acc: 0.7230 - val_loss: 0.8097 - val_acc: 0.7099\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6647 - acc: 0.7098 - val_loss: 0.8421 - val_acc: 0.6908\n",
      "Epoch 44/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6304 - acc: 0.7262 - val_loss: 0.9336 - val_acc: 0.6947\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6207 - acc: 0.7115 - val_loss: 0.8523 - val_acc: 0.7061\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6144 - acc: 0.7164 - val_loss: 0.8657 - val_acc: 0.7252\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6370 - acc: 0.7361 - val_loss: 1.0775 - val_acc: 0.6565\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6147 - acc: 0.7279 - val_loss: 0.8865 - val_acc: 0.7214\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6399 - acc: 0.7361 - val_loss: 1.0664 - val_acc: 0.6565\n",
      "Epoch 50/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 0.6060 - acc: 0.7361 - val_loss: 0.8533 - val_acc: 0.7405\n",
      "5-conv-32-nodes-1-dense-1550887270-5x5-kernal-50epochs-2x2maxpooling\n",
      "Train on 610 samples, validate on 262 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.1009 - acc: 0.3607 - val_loss: 1.0994 - val_acc: 0.3015\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.1064 - acc: 0.3525 - val_loss: 1.1001 - val_acc: 0.3015\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0976 - acc: 0.3574 - val_loss: 1.1026 - val_acc: 0.3015\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0983 - acc: 0.3607 - val_loss: 1.1023 - val_acc: 0.3015\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0971 - acc: 0.3639 - val_loss: 1.1024 - val_acc: 0.3015\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1046 - val_acc: 0.3015\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0975 - acc: 0.3639 - val_loss: 1.1029 - val_acc: 0.3015\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1041 - val_acc: 0.3015\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1044 - val_acc: 0.3015\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1046 - val_acc: 0.3015\n",
      "Epoch 11/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1050 - val_acc: 0.3015\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1046 - val_acc: 0.3015\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0971 - acc: 0.3639 - val_loss: 1.1040 - val_acc: 0.3015\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1049 - val_acc: 0.3015\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0961 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1049 - val_acc: 0.3015\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1044 - val_acc: 0.3015\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0955 - acc: 0.3639 - val_loss: 1.1039 - val_acc: 0.3015\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0980 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 22/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0960 - acc: 0.3639 - val_loss: 1.1046 - val_acc: 0.3015\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0973 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0973 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1060 - val_acc: 0.3015\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1050 - val_acc: 0.3015\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1063 - val_acc: 0.3015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1066 - val_acc: 0.3015\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0961 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1042 - val_acc: 0.3015\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0958 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1061 - val_acc: 0.3015\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0961 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0961 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1060 - val_acc: 0.3015\n",
      "Epoch 44/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1053 - val_acc: 0.3015\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0971 - acc: 0.3639 - val_loss: 1.1049 - val_acc: 0.3015\n",
      "Epoch 50/50\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "5-conv-64-nodes-1-dense-1550887355-5x5-kernal-50epochs-2x2maxpooling\n",
      "Train on 610 samples, validate on 262 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 3s 6ms/step - loss: 1.1076 - acc: 0.3492 - val_loss: 1.0996 - val_acc: 0.3015\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0977 - acc: 0.3639 - val_loss: 1.1009 - val_acc: 0.3015\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0972 - acc: 0.3639 - val_loss: 1.1033 - val_acc: 0.3015\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1025 - val_acc: 0.3015\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0978 - acc: 0.3639 - val_loss: 1.1038 - val_acc: 0.3015\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0972 - acc: 0.3639 - val_loss: 1.1031 - val_acc: 0.3015\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1034 - val_acc: 0.3015\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1041 - val_acc: 0.3015\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1045 - val_acc: 0.3015\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1048 - val_acc: 0.3015\n",
      "Epoch 11/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0973 - acc: 0.3639 - val_loss: 1.1044 - val_acc: 0.3015\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1056 - val_acc: 0.3015\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1050 - val_acc: 0.3015\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1049 - val_acc: 0.3015\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0971 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1043 - val_acc: 0.3015\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1050 - val_acc: 0.3015\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1053 - val_acc: 0.3015\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1059 - val_acc: 0.3015\n",
      "Epoch 22/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0972 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0961 - acc: 0.3639 - val_loss: 1.1056 - val_acc: 0.3015\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1062 - val_acc: 0.3015\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1058 - val_acc: 0.3015\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1048 - val_acc: 0.3015\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1046 - val_acc: 0.3015\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1053 - val_acc: 0.3015\n",
      "Epoch 33/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1059 - val_acc: 0.3015\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1056 - val_acc: 0.3015\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1050 - val_acc: 0.3015\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1058 - val_acc: 0.3015\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1061 - val_acc: 0.3015\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0956 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1048 - val_acc: 0.3015\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0974 - acc: 0.3639 - val_loss: 1.1044 - val_acc: 0.3015\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1058 - val_acc: 0.3015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0961 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1046 - val_acc: 0.3015\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0972 - acc: 0.3639 - val_loss: 1.1048 - val_acc: 0.3015\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0959 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 50/50\n",
      "610/610 [==============================] - 3s 5ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "5-conv-128-nodes-1-dense-1550887501-5x5-kernal-50epochs-2x2maxpooling\n",
      "Train on 610 samples, validate on 262 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 6s 10ms/step - loss: 1.1289 - acc: 0.3557 - val_loss: 1.0710 - val_acc: 0.4618\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.1324 - acc: 0.3689 - val_loss: 1.1012 - val_acc: 0.3015\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.1013 - acc: 0.3393 - val_loss: 1.1012 - val_acc: 0.3015\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1029 - val_acc: 0.3015\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1040 - val_acc: 0.3015\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.0973 - acc: 0.3639 - val_loss: 1.1030 - val_acc: 0.3015\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1038 - val_acc: 0.3015\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0974 - acc: 0.3639 - val_loss: 1.1040 - val_acc: 0.3015\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1034 - val_acc: 0.3015\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0972 - acc: 0.3639 - val_loss: 1.1036 - val_acc: 0.3015\n",
      "Epoch 11/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1039 - val_acc: 0.3015\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1042 - val_acc: 0.3015\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0973 - acc: 0.3639 - val_loss: 1.1041 - val_acc: 0.3015\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1045 - val_acc: 0.3015\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1056 - val_acc: 0.3015\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1059 - val_acc: 0.3015\n",
      "Epoch 22/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0960 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1056 - val_acc: 0.3015\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1048 - val_acc: 0.3015\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1052 - val_acc: 0.3015\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1047 - val_acc: 0.3015\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0973 - acc: 0.3639 - val_loss: 1.1058 - val_acc: 0.3015\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0972 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0974 - acc: 0.3639 - val_loss: 1.1053 - val_acc: 0.3015\n",
      "Epoch 33/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0968 - acc: 0.3639 - val_loss: 1.1048 - val_acc: 0.3015\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0975 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0966 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1053 - val_acc: 0.3015\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0970 - acc: 0.3639 - val_loss: 1.1057 - val_acc: 0.3015\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0964 - acc: 0.3639 - val_loss: 1.1059 - val_acc: 0.3015\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0963 - acc: 0.3639 - val_loss: 1.1056 - val_acc: 0.3015\n",
      "Epoch 44/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0958 - acc: 0.3639 - val_loss: 1.1059 - val_acc: 0.3015\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1053 - val_acc: 0.3015\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0969 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3015\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0962 - acc: 0.3639 - val_loss: 1.1054 - val_acc: 0.3015\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0957 - acc: 0.3639 - val_loss: 1.1055 - val_acc: 0.3015\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0967 - acc: 0.3639 - val_loss: 1.1060 - val_acc: 0.3015\n",
      "Epoch 50/50\n",
      "610/610 [==============================] - 5s 9ms/step - loss: 1.0965 - acc: 0.3639 - val_loss: 1.1058 - val_acc: 0.3015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\'import tensorflow as tf\\nfrom tensorflow.keras.datasets import cifar10\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\\n\\nimport pickle\\n\\n\\n# importing the libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as mpl\\nimport matplotlib.pyplot as plt\\nfrom glob import glob\\nfrom keras.preprocessing.image import ImageDataGenerator\\n#from keras.applications.vgg16 import preprocess_input\\n#from keras.models import Sequential\\n#from keras.applications import VGG16 \\n#from keras.layers import Activation, Dense\\nimport os\\n\\n\\nfrom keras.preprocessing.image import ImageDataGenerator\\n\\nimport keras \\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\\nfrom keras.callbacks import TensorBoard\\n# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\\nfrom tensorflow.keras.callbacks import TensorBoard\\n\\nimport matplotlib.pyplot as plt\\nimport time\\n\\n\\nNAME = \"CNN-kaggel-dataset-50epochs-2dropout-4cov2d-x200-30%split-184_42_64-7x7-no-dense\"\\n\\ntensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\\n\\n\\n\\n\\npickle_in = open(\"X.pickle\",\"rb\")\\nX = pickle.load(pickle_in)\\n\\npickle_in = open(\"y.pickle\",\"rb\")\\ny = pickle.load(pickle_in)\\n\\nX = X/255.0\\n\\n# keras part .............\\n\\n# Generate dummy data\\n#import numpy as np\\n#data = np.random.random((1000, 100))\\n#labels = np.random.randint(10, size=(1000, 1))\\n\\n# Convert labels to categorical one-hot encoding\\none_hot_labels = keras.utils.to_categorical(y, num_classes=3)\\n\\n# Train the model, iterating on the data in batches of 32 samples\\n#model.fit(data, one_hot_labels, epochs=10, batch_size=32)\\n\\n#end keras part...........\\n\\n\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(184, (7, 7), activation =\\'relu\\', input_shape=(200, 200, 3)))\\nmodel.add(MaxPool2D(pool_size=(4, 4)))\\n\\nmodel.add(Conv2D(42, (7, 7), activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(4, 4)))\\n\\nmodel.add(Conv2D(42, (7, 7), activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(4, 4)))\\n\\nmodel.add(Conv2D(64, (7, 7), strides = 1, activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(4, 4)))\\nmodel.add(Dropout(0.25))\\nmodel.add(Flatten())\\n#model.add(Dense(64, activation =\\'relu\\'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(3, activation =\\'softmax\\'))\\n\\nmodel.compile(loss=\\'categorical_crossentropy\\',\\n              optimizer=\\'adam\\',\\n              metrics=[\\'accuracy\\'])\\n\\nhistory=model.fit(X, one_hot_labels, batch_size=32, epochs=50, validation_split=0.3,callbacks=[tensorboard])\\n#model.evaluate_\\n\\n\\n#score,acc=model.evaluate(X)\\n\\nprint(history.history.keys())\\n\\nplt.plot(history.history[\\'val_acc\\'])\\nplt.plot(history.history[\\'acc\\'])\\nplt.title(\\'model accuracy\\')\\nplt.ylabel(\\'accuracy\\')\\nplt.xlabel(\\'epoch\\')\\nplt.legend([\\'train\\', \\'validation\\'], loc=\\'upper left\\')\\nplt.show()\\n# summarize history for loss\\nplt.plot(history.history[\\'loss\\'])\\nplt.plot(history.history[\\'val_loss\\'])\\nplt.title(\\'model loss\\')\\nplt.ylabel(\\'loss\\')\\nplt.xlabel(\\'epoch\\')\\nplt.legend([\\'train\\', \\'validation\\'], loc=\\'upper left\\')\\nplt.show()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.models import Sequential\n",
    "#from keras.applications import VGG16 \n",
    "#from keras.layers import Activation, Dense\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "            \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "#gpu_options= tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "#sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "one_hot_labels = keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "dense_layers = [0,1]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers = [1,2,3,4,5]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}-5x5-kernal-50epochs-2x2maxpooling\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "            tensorboard = TensorBoard(log_dir=\"newtraining/{}\".format(NAME))\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (5, 5), input_shape=(200, 200, 3)))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (5, 5)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "                \n",
    "            model.add(Dropout(0.25))\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(1))\n",
    "            model.add(Dense(3, activation ='softmax'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, one_hot_labels,\n",
    "                      batch_size=10,\n",
    "                      epochs=50,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''''import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.models import Sequential\n",
    "#from keras.applications import VGG16 \n",
    "#from keras.layers import Activation, Dense\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "NAME = \"CNN-kaggel-dataset-50epochs-2dropout-4cov2d-x200-30%split-184_42_64-7x7-no-dense\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "# keras part .............\n",
    "\n",
    "# Generate dummy data\n",
    "#import numpy as np\n",
    "#data = np.random.random((1000, 100))\n",
    "#labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "#model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n",
    "\n",
    "#end keras part...........\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(184, (7, 7), activation ='relu', input_shape=(200, 200, 3)))\n",
    "model.add(MaxPool2D(pool_size=(4, 4)))\n",
    "\n",
    "model.add(Conv2D(42, (7, 7), activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4)))\n",
    "\n",
    "model.add(Conv2D(42, (7, 7), activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4)))\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), strides = 1, activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(64, activation ='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation ='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X, one_hot_labels, batch_size=32, epochs=50, validation_split=0.3,callbacks=[tensorboard])\n",
    "#model.evaluate_\n",
    "\n",
    "\n",
    "#score,acc=model.evaluate(X)\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
