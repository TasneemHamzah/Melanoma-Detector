{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 316 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "316/316 [==============================] - 3s 9ms/step - loss: 1.2766 - acc: 0.4873 - val_loss: 0.6720 - val_acc: 0.6111\n",
      "Epoch 2/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.7016 - acc: 0.5063 - val_loss: 0.6755 - val_acc: 0.6111\n",
      "Epoch 3/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.6883 - acc: 0.5411 - val_loss: 0.6742 - val_acc: 0.6111\n",
      "Epoch 4/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.6847 - acc: 0.5348 - val_loss: 0.6884 - val_acc: 0.4167\n",
      "Epoch 5/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.6809 - acc: 0.5253 - val_loss: 0.6727 - val_acc: 0.6667\n",
      "Epoch 6/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.6600 - acc: 0.6424 - val_loss: 0.6278 - val_acc: 0.6667\n",
      "Epoch 7/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.6383 - acc: 0.6234 - val_loss: 0.5932 - val_acc: 0.6944\n",
      "Epoch 8/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.5969 - acc: 0.6772 - val_loss: 0.6062 - val_acc: 0.6667\n",
      "Epoch 9/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.5468 - acc: 0.6930 - val_loss: 0.6005 - val_acc: 0.6667\n",
      "Epoch 10/20\n",
      "316/316 [==============================] - 1s 3ms/step - loss: 0.5071 - acc: 0.7278 - val_loss: 0.4814 - val_acc: 0.8056\n",
      "Epoch 11/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.4858 - acc: 0.7848 - val_loss: 0.5501 - val_acc: 0.6667\n",
      "Epoch 12/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.4943 - acc: 0.7595 - val_loss: 0.5622 - val_acc: 0.6944\n",
      "Epoch 13/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.4947 - acc: 0.7595 - val_loss: 0.5522 - val_acc: 0.6944\n",
      "Epoch 14/20\n",
      "316/316 [==============================] - 1s 3ms/step - loss: 0.4678 - acc: 0.7816 - val_loss: 0.5929 - val_acc: 0.7222\n",
      "Epoch 15/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.5158 - acc: 0.7500 - val_loss: 0.6599 - val_acc: 0.6389\n",
      "Epoch 16/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.4589 - acc: 0.7595 - val_loss: 0.4974 - val_acc: 0.7500\n",
      "Epoch 17/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.3942 - acc: 0.8133 - val_loss: 0.4825 - val_acc: 0.7778\n",
      "Epoch 18/20\n",
      "316/316 [==============================] - 1s 3ms/step - loss: 0.3658 - acc: 0.8354 - val_loss: 0.5690 - val_acc: 0.7500\n",
      "Epoch 19/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.3132 - acc: 0.8544 - val_loss: 0.7944 - val_acc: 0.7222\n",
      "Epoch 20/20\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.3120 - acc: 0.8576 - val_loss: 0.6401 - val_acc: 0.7500\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.models import Sequential\n",
    "#from keras.applications import VGG16 \n",
    "#from keras.layers import Activation, Dense\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "NAME = \"CNN-second-dataset-balance-15epochs-one-dropout-3cov2d-x200\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "# keras part .............\n",
    "\n",
    "# Generate dummy data\n",
    "#import numpy as np\n",
    "#data = np.random.random((1000, 100))\n",
    "#labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "#one_hot_labels = keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "#model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n",
    "\n",
    "#end keras part...........\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation ='relu', input_shape=(200, 200, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), strides = 1, activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation ='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X, y, batch_size=32, epochs=20, validation_split=0.1,callbacks=[tensorboard])\n",
    "#model.evaluate(test_batches,)\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
